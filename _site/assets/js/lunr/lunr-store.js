var store = [{
        "title": "Large Concept Models: Exploring Semantic Representations Beyond Tokens",
        "excerpt":"Introduction This post highlights the work presented in the paper “Large Concept Models” (Arxiv Link), which proposes a novel approach to move beyond token-based language modeling by introducing higher-level semantic representations called concepts. Summary Large Language Models (LLMs) have become the foundation of modern AI systems, primarily processing input and...","categories": ["AI","Language Models"],
        "tags": ["Concept Models","LLMs","Embeddings","Multilingual","Zero-shot","YouTube"],
        "url": "/ai/language%20models/2025/01/05/large-concept-model.html",
        "teaser": null
      },{
        "title": "Model Distillation: Building High-Performance Small Language Models",
        "excerpt":"Model Distillation: Building High-Performance Small Language Models This is a YouTube video explaining model distillation, an advanced technique to build high-performance small language models at a reasonable cost. It introduces two popular techniques for distillation: Logits Distillation Hidden States Distillation The video explores how these methods work and how they’re...","categories": ["AI","Machine Learning"],
        "tags": ["Distillation","Arcee","Deep Learning","NLP","YouTube"],
        "url": "/ai/machine%20learning/2025/01/05/sample-post.html",
        "teaser": null
      },]
